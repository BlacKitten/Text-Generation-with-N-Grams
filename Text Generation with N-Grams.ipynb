{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences: 22180\n",
      "Number of Tokens: 367891\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import os\n",
    "\n",
    "if os.path.isfile('The Eye of the World - Robert Jordan.txt'): \n",
    "    f = open('The Eye of the World - Robert Jordan.txt', encoding=\"utf8\")\n",
    "    content = f.read()\n",
    "    content = \" \".join(content.lower().split())\n",
    "    sent_tokenize_list = sent_tokenize(content)\n",
    "    content = nltk.word_tokenize(content)\n",
    "    print(\"Number of Sentences:\", len(sent_tokenize_list))\n",
    "    print(\"Number of Tokens:\", len(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def createUnigramCount(content):\n",
    "    unigram = ngrams(content, 1)\n",
    "    model = defaultdict(lambda: 0)\n",
    "    for i in content:\n",
    "        for word1 in unigram:\n",
    "            #print(word1)\n",
    "            model[word1] += 1\n",
    "    return model\n",
    "\n",
    "def createBigramCount(content):\n",
    "    bigram = ngrams(content, 2)\n",
    "    model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    for i in content:\n",
    "        for word1, word2 in bigram:\n",
    "            model[word1][word2] += 1\n",
    "    return model\n",
    "\n",
    "def createTrigramCount(content):\n",
    "    trigram = ngrams(content, 3)\n",
    "    model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    for i in content:\n",
    "        for word1, word2, word3 in trigram:\n",
    "            model[(word1, word2)][word3] += 1\n",
    "    return model\n",
    "\n",
    "def createFourgramCount(content):\n",
    "    fourgram = ngrams(content, 4)\n",
    "    model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    for i in content:\n",
    "        for word1, word2, word3, word4 in fourgram:\n",
    "            model[(word1, word2, word3)][word4] += 1\n",
    "    return model\n",
    "\n",
    "unigramCount = createUnigramCount(content)\n",
    "bigramCount = createBigramCount(content)\n",
    "trigramCount = createTrigramCount(content)\n",
    "fourgramCount = createFourgramCount(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram:\n",
      "The weather or have trollocs had shouted as she realized what did not decide. With his gaze, the room. If by tapping a large space taken an apple cider, he stood in. A round his knees. . He was crisply dark one’ s eye is rarely did teach you. ” the great lord captain domon isn’ alzamon. ” egwene and moiraine sedai are the boy, and her head ; her eyes regarded them. She stood open. It, rand remained whole day or daughter was coming looking at midday. The size again and aching, as if he smiled. Nynaeve’ ll never heard them after all right here. ” moiraine did not more than the inn was gone back there were just the cabinetmaker—would see about that set off her fervently he said his head.\n",
      "\n",
      "Trigram:\n",
      "The big gray felt wolves tearing at their first step another strike at them even with an anxious cluster. The warder. “ lan will be little rest for privacy, he did not appear to expect an answer. One of the arinelle. The ground all about them! ” moiraine replied. “ all things. Lews therin kinslayer, for sure if he delayed just a fever-dream, and called out, and he did the. . .\n",
      "\n",
      "Four-gram:\n",
      "The very center of the big rock was rounded somewhat, with a sharp crack, and the two women were handling him as if he really was feeling better, he realized, but he hoped she would not prefer the palace, the tom was the only person he saw, but it faded away, but no one slowed down. The man moved like a viper. While her blow still fell, balthamel’ s leather-cased hand darted out to push back his coat sleeve. “ rest, and eat, but his head spun and everything he looked at the cart felt the same ; others changed with ten miles’ distance, and the woman in silk. But it turned out the treasure had belonged to one family or another that he knew anything at all could be out there in the palace gardens, claiming to be the lady moiraine walked away, really looked for the first time loial seemed as eager to go on, half reluctant to do so. “ we have to hurry and hope. The shrill cries that had hounded them faded as they rode a little closer, he saw, and that’ s saying some ill chance doesn’ t come back tomorrow and help you. ” rand tightened his grip on something. The innkeeper was hurrying them out the back! ” the ogier paused, rubbing the bridge of his broad nose thoughtfully. Finally he straightened.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def unigramPredict(content, numOfSentences):\n",
    "    unigramKeys = []\n",
    "    for i in list(unigramCount.keys()):\n",
    "        unigramKeys.append(i[0])\n",
    "    sentence = []\n",
    "    count = 0\n",
    "    punctuations = ['.', '!', '?', '\"']\n",
    "    while count < numOfSentences:\n",
    "        randomToken = np.random.choice(unigramKeys, 1, p = [float(i)/(sum(unigramCount.values())) for i in unigramCount.values()])[0]\n",
    "        if randomToken in punctuations:\n",
    "            count += 1\n",
    "        print(randomToken)\n",
    "        sentence.append(randomToken)\n",
    "    return sentence\n",
    "\n",
    "def bigramPredict(content, seed, numOfSentences):\n",
    "    sentence = seed.split()\n",
    "    count = 0\n",
    "    punctuations = ['.', '!', '?', '\"']\n",
    "    while count < numOfSentences:\n",
    "        randomToken = np.random.choice(list(bigramCount[sentence[-1]]), 1, p = [float(i)/(sum(bigramCount[sentence[-1]].values())) for i in bigramCount[sentence[-1]].values()])[0]\n",
    "        if randomToken in punctuations:\n",
    "            count += 1\n",
    "        sentence.append(randomToken)\n",
    "    return sentence\n",
    "\n",
    "def trigramPredict(content, seed, numOfSentences):\n",
    "    sentence = seed.split()\n",
    "    randomToken = np.random.choice(list(bigramCount[sentence[-1]]), 1, p = [float(i)/(sum(bigramCount[sentence[-1]].values())) for i in bigramCount[sentence[-1]].values()])[0]\n",
    "    sentence.append(randomToken)\n",
    "    count = 0\n",
    "    punctuations = ['.', '!', '?', '\"']\n",
    "    while count < numOfSentences:\n",
    "        if len(trigramModel[(sentence[-2], sentence[-1])]) == 0:\n",
    "            randomToken = np.random.choice(list(bigramCount[sentence[-1]]), 1, p = [float(i)/(sum(bigramCount[sentence[-1]].values())) for i in bigramCount[sentence[-1]].values()])[0]\n",
    "        else:\n",
    "            randomToken = np.random.choice(list(trigramCount[(sentence[-2], sentence[-1])]), 1, p = [float(i)/(sum(trigramCount[(sentence[-2], sentence[-1])].values())) for i in trigramCount[(sentence[-2], sentence[-1])].values()])[0]\n",
    "        if randomToken in punctuations:\n",
    "            count += 1\n",
    "        sentence.append(randomToken)\n",
    "    return sentence\n",
    "\n",
    "def fourgramPredict(content, seed, numOfSentences):\n",
    "    sentence = seed.split()\n",
    "    randomToken = np.random.choice(list(bigramCount[sentence[-1]]), 1, p = [float(i)/(sum(bigramCount[sentence[-1]].values())) for i in bigramCount[sentence[-1]].values()])[0]\n",
    "    sentence.append(randomToken)\n",
    "    randomToken = np.random.choice(list(trigramCount[(sentence[-2], sentence[-1])]), 1, p = [float(i)/(sum(trigramCount[(sentence[-2], sentence[-1])].values())) for i in trigramCount[(sentence[-2], sentence[-1])].values()])[0]\n",
    "    sentence.append(randomToken)\n",
    "    count = 0\n",
    "    punctuations = ['.', '!', '?', '\"']\n",
    "    while count < numOfSentences:\n",
    "        if len(fourgramCount[(sentence[-3], sentence[-2], sentence[-1])]) == 0:\n",
    "            if len(trigramCount[(sentence[-2], sentence[-1])]) == 0:\n",
    "                randomToken = np.random.choice(list(bigramCount[sentence[-1]]), 1, p = [float(i)/(sum(bigramCount[sentence[-1]].values())) for i in bigramCount[sentence[-1]].values()])[0]\n",
    "            else:\n",
    "                randomToken = np.random.choice(list(trigramCount[(sentence[-2], sentence[-1])]), 1, p = [float(i)/(sum(trigramCount[(sentence[-2], sentence[-1])].values())) for i in trigramCount[(sentence[-2], sentence[-1])].values()])[0]\n",
    "        else:\n",
    "            randomToken = np.random.choice(list(fourgramCount[(sentence[-3], sentence[-2], sentence[-1])]), 1, p = [float(i)/(sum(fourgramCount[(sentence[-3], sentence[-2], sentence[-1])].values())) for i in fourgramCount[(sentence[-3], sentence[-2], sentence[-1])].values()])[0]\n",
    "        if randomToken in punctuations:\n",
    "            count += 1\n",
    "        sentence.append(randomToken)\n",
    "    return sentence\n",
    "\n",
    "def generate(ls):\n",
    "    output = ls[0].capitalize()\n",
    "    for token in ls[1:]:\n",
    "        if output[-1] in ['.', '!', '?'] or token == 'i':\n",
    "            output += \" \" + token.capitalize()\n",
    "        elif token in [',', \"’\", '”', ':', '.', '!', '?']:\n",
    "            output += token\n",
    "        else:\n",
    "            output += \" \" + token\n",
    "    return output\n",
    "\n",
    "print(\"Bigram:\")\n",
    "print(generate(bigramPredict(content, 'the', 10)))\n",
    "print()\n",
    "print(\"Trigram:\")\n",
    "print(generate(trigramPredict(content, 'the', 10)))\n",
    "print()\n",
    "print(\"Four-gram:\")\n",
    "print(generate(fourgramPredict(content, 'the', 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "np.random.seed(1)\n",
    "random.shuffle(sent_tokenize_list)\n",
    "\n",
    "trainSet = sent_tokenize_list[: int(len(sent_tokenize_list) * 0.9)] # 90%\n",
    "testSet = sent_tokenize_list[int(len(sent_tokenize_list) * 0.9):] # 10%\n",
    "flatten = ' '.join(trainSet)\n",
    "flatten = nltk.word_tokenize(flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515.399937964938\n",
      "83.58977846088527\n",
      "45.045136485957954\n",
      "32.7965663761686\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "unigramModel = createUnigramCount(flatten)\n",
    "bigramModel = createBigramCount(flatten)\n",
    "trigramModel = createTrigramCount(flatten)\n",
    "fourgramModel = createFourgramCount(flatten)\n",
    "\n",
    "def perplexityUnigram(testSet):\n",
    "    summation = 0\n",
    "    words = 0\n",
    "    for s in testSet:\n",
    "        tokens = nltk.word_tokenize(s)\n",
    "        words += len(tokens)\n",
    "        for index, word in enumerate(tokens):\n",
    "            p = (unigramModel[(tokens[index],)] + 0.1)/(sum(unigramModel.values()) + (0.1 * len(unigramModel.values())))\n",
    "            summation += math.log(p, 2)\n",
    "    average = summation/words\n",
    "    return pow(2, -average)\n",
    "\n",
    "def perplexityBigram(testSet):\n",
    "    summation = 0\n",
    "    words = 0\n",
    "    for s in testSet:\n",
    "        tokens = nltk.word_tokenize(s)\n",
    "        words += len(tokens)\n",
    "        for index, word in enumerate(tokens):\n",
    "            if index > 0:\n",
    "                if bigramModel[tokens[index - 1]][tokens[index]] == 0:\n",
    "                    p = (unigramModel[(tokens[index],)] + 0.1)/(sum(unigramModel.values()) + (0.1 * len(unigramModel.values())))\n",
    "                else:\n",
    "                    p = (bigramModel[tokens[index - 1]][tokens[index]])/(sum(bigramModel[tokens[index - 1]].values()))                \n",
    "                summation += math.log(p, 2)\n",
    "    average = summation/words\n",
    "    return pow(2, -average)\n",
    "\n",
    "def perplexityTrigram(testSet):\n",
    "    summation = 0\n",
    "    words = 0\n",
    "    for s in testSet:\n",
    "        tokens = nltk.word_tokenize(s)\n",
    "        words += len(tokens)\n",
    "        for index, word in enumerate(tokens):\n",
    "            if index > 1:\n",
    "                if trigramModel[(tokens[index - 2], tokens[index - 1])][tokens[index]] == 0:\n",
    "                    if bigramModel[tokens[index - 1]][tokens[index]] == 0:\n",
    "                        p = (unigramModel[(tokens[index],)] + 0.1)/(sum(unigramModel.values()) + (0.1 * len(unigramModel.values())))\n",
    "                    else:\n",
    "                        p = (bigramModel[tokens[index - 1]][tokens[index]])/(sum(bigramModel[tokens[index - 1]].values()))\n",
    "                else:\n",
    "                    p = (trigramModel[(tokens[index - 2], tokens[index - 1])][tokens[index]])/(sum(trigramModel[(tokens[index - 2], tokens[index - 1])].values()))                \n",
    "                summation += math.log(p, 2)\n",
    "    average = summation/words\n",
    "    return pow(2, -average)\n",
    "\n",
    "def perplexityFourgram(testSet):\n",
    "    summation = 0\n",
    "    words = 0\n",
    "    for s in testSet:\n",
    "        tokens = nltk.word_tokenize(s)\n",
    "        words += len(tokens)\n",
    "        for index, word in enumerate(tokens):\n",
    "            if index > 2:\n",
    "                if fourgramModel[(tokens[index - 3], tokens[index - 2], tokens[index - 1])][tokens[index]] == 0:\n",
    "                    if trigramModel[(tokens[index - 2], tokens[index - 1])][tokens[index]] == 0:\n",
    "                        if bigramModel[tokens[index - 1]][tokens[index]] == 0:\n",
    "                            p = (unigramModel[(tokens[index],)] + 0.1)/(sum(unigramModel.values()) + (0.1 * len(unigramModel.values())))\n",
    "                        else:\n",
    "                            p = (bigramModel[tokens[index - 1]][tokens[index]])/(sum(bigramModel[tokens[index - 1]].values()))\n",
    "                    else:\n",
    "                        p = (trigramModel[(tokens[index - 2], tokens[index - 1])][tokens[index]])/(sum(trigramModel[(tokens[index - 2], tokens[index - 1])].values()))\n",
    "                else:\n",
    "                    p = (fourgramModel[(tokens[index - 3], tokens[index - 2], tokens[index - 1])][tokens[index]])/sum(fourgramModel[(tokens[index - 3], tokens[index - 2], tokens[index - 1])].values())\n",
    "                summation += math.log(p, 2)\n",
    "    average = summation/words\n",
    "    return pow(2, -average)\n",
    "\n",
    "print(perplexityUnigram(testSet))\n",
    "print(perplexityBigram(testSet))\n",
    "print(perplexityTrigram(testSet))\n",
    "print(perplexityFourgram(testSet))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
